# С чего все началось

Предположим, мы хотим заставить нашу вычислительную машину выполнять за нас скучные и нелюбимые многими математические операции.

До создания такой вещи, как высокоуровневые языки программирования, люди писали на ассемблере. Ещё раньше писали в машинных кодах, т.е. буквально нулями и единицами, но ассемблер, по сути, является буквенным представлением машинных кодов, поэтому не будем на них останавливаться.

Пусть, для примера, мы хотим посчитать `(a + b - c) / (a * 2)` для 16-разрядных целых чисел без знака. Разрядность, наличие знака и то, являются ли числа целыми или дробными, для программы на ассемблере важно.

~~~asm
format PE console                            ; 32-разрядная консольная программа WINDOWS EXE
entry start                                  ; точка входа

include 'include\win32a.inc'

section '.idata' import data readable        ; секция импортируемых функций

library kernel,'kernel32.dll',\
        msvcrt,'msvcrt.dll'

import  kernel,\
        ExitProcess,'ExitProcess'

import  msvcrt,\
        printf,'printf',\
        getchar,'_fgetchar'

section '.data' data readable writeable      ; секция данных

A dw 260                                     ; первое число
B dw 600                                     ; второе число
C dw 534                                     ; третье число

MESSAGE db "Result is %d",10,0               ; текст сообщения

section '.code' code readable executable     ; секция кода

start:                                       ; точка входа в программу
    xor eax, eax
    mov ax, [A]
    mov ecx, 2
    mul ecx
    mov ecx, eax
    ; конец скобки 2
    ; значение в ecx

    ; начало скобки 1
    xor eax, eax
    mov ax, [A]
    movzx ebx, ax
    mov ax, [B]
    add ebx, eax
    xor eax, eax
    mov ax, [C]
    sub ebx, eax
    mov eax, ebx
    ; конец скобки 1
    ; значение в eax

    div ecx                                 ; делим скобку_1 на скобку_2

    ccall [printf], MESSAGE, eax            ; вывод сообщения с результатом
    ccall [getchar]                         ; ожидание ввода
    stdcall [ExitProcess],0                 ; корректное завершение программы
~~~

Если скомпилировать программу и запустить полученный `.exe`-файл, то мы увидим в консоли результат вычисления выражения `(a + b - c) / (a * 2)` для A =  260, B = 600, C = 534 (ввод произвольных чисел слишком громоздкий). 

Видно, что даже такие примитивные программы на ассемблере достаточно сложны.

Если вы, увидев эту программу, скажете «слишком сложно, давай легче», то будете не первыми. Именно сложность программ на ассемблере и количество ошибок в них привели к тому, что люди задумались о создании высокоуровневых языков программирования. 

Что значит высокоуровневые языки? Различают 2 типа языков программирования:

1. Низкоуровневые языки: машинные коды, ассемблер и т.д.
0. Высокоуровневые языки: C#, Python и т.д.

Высокоуровневый язык программирования - язык программирования, разработанный для быстроты и удобства использования программистом. Основная черта высокоуровневых языков — это абстракция, то есть введение смысловых конструкций, кратко описывающих структуры данных и операции над ними, описания которых на машинном коде (или другом низкоуровневом языке программирования) очень длинны и сложны для понимания.

Высокоуровневые языки программирования были разработаны для платформенной независимости сути алгоритмов. Зависимость от платформы перекладывается на инструментальные программы — трансляторы, компилирующие текст, написанный на языке высокого уровня, в элементарные машинные команды (инструкции). Поэтому, для каждой платформы разрабатывается платформенно-уникальный транслятор для каждого высокоуровневого языка, например, переводящий текст, написанный на Delphi, в элементарные команды микропроцессоров.

# Вводное в теорию языков

Естественные языки и языки программирования во многом схожи, поэтому многое, что относится к одним, относится и к другим. Примеры на человеческом языке проще воспринимаются, поэтому я буду использовать их, где возможно.

Любой язык состоит из трёх компонент: словаря, синтаксиса и семантики.

Словарь – это множество лексем, принадлежащих языку. \
Лексема – это множество форм одного и того же слова (в языках программирования у слов нет форм, так что по этому поводу можно не париться). \
Синтаксис – это правила построения языковых конструкций. Для обычных языков это правила построения предложений и текстов, для языков программирования – общая структура программ и библиотек (в каком порядке надо писать какие ключевые слова и т.д.). \
Семантика – это смысл предложения или программы. 

Задача трансляции – это, по сути, перевод текста с одного языка на другой. При этом разные языки имеют разные словари и разный синтаксис, и возникает вопрос, как именно надо переводить.

Простая тупая замена каждого слова соответствующим словом из другого языка, как правило, не работает. Примером частично является «потраченный» перевод GTA SA: «ВОЗМОЖНО ЯВЛЯЕТСЯ ТОЛЬКО ДЛЯ».

Более того, для естественных языков далеко не всегда работает и синтаксический перевод. Фраза может получиться допустимой с точки зрения грамматики, но не имеющей никакого смысла: «Вам нужен новый гуртовщик мыши. Если вы пользователь Microsoft мыши, посетите Microsoft Слугу Паутины, где в особом подвале вы сможете опустить-загрузить самого текущего гуртовщика Microsoft мыши. Если производитель вашей мыши другой, узнайте о ее гуртовщике. Все основные производители мыши уже имеют гуртовщиков мыши для Окон 95».

Вывод: при переводе главное – это сохранить смысл текста. Переводчики говорят, что лучший результат при переводе получается не в том случае, когда переводчик переводит слово в слово, а тогда, когда он, прочитав текст на исходном языке, делает письменный его пересказ на другом языке (с опорой на первоначальный текст).

Таким образом, для перевода текста с одного языка на другой нужно понять его смысл и передать его на другом языке. В общем случае (для вообще любого языка) это с помощью программы сделать невозможно.

Хорошие новости – языки программирования созданы таким образом, что, во-первых, их всегда можно перевести как минимум на машинный язык, во-вторых, смысл текста на них полностью определяется синтаксисом, так что про семантику можно забыть.

Итак, для перевода с одного языка программирования на другой нужно выделить в тексте слова, понять синтаксическую структуру предложения, заменить структуру на структуру другого языка и вставить туда слова из другого языка.

Вначале идёт выделение лексем – этим занимается лексический анализатор. Не стоит забывать, что лексема в трансляции – это не совсем то же, что и слово в обычном понимании, например, запятую можно считать лексемой, а словом – нельзя, но в целом можно говорить о разбиении текста на слова. Например, если на вход лексеру подаётся предложение «Мама мыла раму.», то он должен выдать: [«Мама», «мыла», «раму», «.»]. Если на вход подаётся такая программа:

~~~C++
int main() {
    printf("Hello, world!");
    return 0;
}
~~~
то на выходе должно быть:

~~~
[«int», «main», «(», «)», «{», «printf», «(», «”Hello, world”», «)», «;», «return», «0», «;», «}» ]
~~~

или же если рассматривать код на Python

~~~Python
def main():
    print("Hello, world")
    return 0
~~~

Естественно, в разных языках разные правила для лексем. Например, как можно здесь видеть, «Hello, world» для C – это одна лексема, хотя это вроде бы два слова да плюс запятая. Составить эти правила – задача либо для разработчика языка, либо для разработчика транслятора.

Итак, лексический анализатор от разработчика получает правила для распознавания лексем и от пользователя получает текст, этот текст разбивает на лексемы по заданным правилам и эти лексемы выдаёт в понятном для компьютера виде – в массиве.

Далее лексемы подаются в синтаксический анализатор. Он по заданным правилам грамматики определяет структуру предложения.

Здесь требуется хотя бы базовое знание грамматик Хомского – хотя бы знание обозначений и понимание того, что такое терминалы и нетерминалы.

Язык здесь – это множество различных последовательностей лексем. Язык, порождённый какой-либо грамматикой – это все последовательности лексем, которые могут быть получены с помощью данной грамматики.

Грамматики Хомского – совокупность терминалов, нетерминалов, начального символа и правил вывода.

Выражаясь человеческим языком, грамматика Хомского – такая штука, которая позволяет по каким-то правилам преобразовывать одни строки в другие (или, как говорят, выводить цепочки). При этом в начале строка состоит только из начального символа, а в конце состоит только из терминалов – либо вообще не состоит из чего-либо, т.е. является пустой строкой.

Терминалы и нетерминалы в общем называются «символы». В тренировочных примерах их обычно обозначают одной буквой, хотя вообще их можно обозначать как угодно, лишь бы было понятно. однако если выдали задание на грамматики Хомского, то лучше таки писать их одной буквой.

Нетерминалы – это символы, которые потом ещё будут заменяться. Они обычно представляют собой какие-то конструкции или обороты естественного языка или языка программирования – подробней об этом потом. Обозначаются либо большими латинскими буквами, либо словами в угловых скобках.

Терминалы – символы, на которых вывод заканчивается. В примерах они обозначаются маленькими латинскими буквами. Это слова или знаки препинания естественного языка, или ключевые слова и прочее для языка программирования.

вообще есть грамматики, где на терминалах вывод не заканчивается, но об этом позже.

Правила, по которым производится преобразование, называются «продукции». В общем виде они имеют вид

`α → β`, где `α` – исходная подцепочка, которую можно затем заменить на подцепочку `β` (дальше я буду вместо → писать =, ибо мне лень).

Например, если посреди вывода у нас есть цепочка AbCdE,и есть правило вида AbC = B, то мы можем превратить ту цепочку в вот такую: BdE Не буду расписывать всю классификацию грамматик Хомского, напишу лишь, что особо выделяют контекстно-свободные (КС) грамматики. В них в левых частях есть только один нетерминал, и всё. Это даёт два важных свойства: – каждый нетерминал можно заменять независимо от других – терминалы, однажды появившись, никуда не исчезают и ни во что не превращаются. С такими грамматиками относительно просто работать – как только все нетерминалы заменены на терминалы, вывод окончен. При этом правила вполне могут быть рекурсивными и порождать сколь угодно большие цепочки, это нормально.

Начальный символ (аксиома) – это нетерминал, с которого начинается вывод любой цепочки языка данной грамматики. Да, начальный символ важен – грамматики, различающиеся только начальным символом, могут порождать разные языки. Например, грамматика с множеством нетерминалов `{O, Z}`, множеством терминалов `{0, 1}`, начальным символом `O` и продукциями: `O = 1Z | 1` `Z = 0O | 0` порождает цепочки вида `1010101010`, начинающиеся с единицы, а если бы начальный символ был `Z`, то все цепочки порождаемого им языка начинались бы с `0`.

Вернёмся к синтаксическому анализатору. Пример: Предположим, что русский язык имеет такую грамматику:
~~~
<предложение> = <группа подлежащего> <группа сказуемого>. | <группа сказуемого> <группа подлежащего>.
<группа подлежащего> = <подлежащее> 
<группа сказуемого> =  [<дополнение >] <сказуемое> [<дополнение>]
<дополнение> = <существительное>
<подлежащее> = <существительное>
<сказуемое> = <глагол>
<существительное> = мама | рама
<глагол> = мыть
~~~

Для примера можно забыть про формы слов, это здесь несущественно. Тогда предложение «Мама мыла раму.» можно построить так: `<предложение> = <группа подлежащего> <группа сказуемого>. = <подлежащее> <сказуемое> <дополнение>. = <существительное> <глагол> <существительное>. = Мама мыла раму`. Кстати, лексер для этого предложения выдаст [«Мама», «мыть», «рама», «.»] Да, точка здесь важна, это терминал, входящий в правила синтаксиса.

Может показаться не совсем понятным, зачем всё это делать. Всё это делается для того, чтобы понять, что к чему относится. Если бы все предложения строились по схеме «Кто-то сделал что-то», то анализ был бы не нужен, и переводить было бы легко и просто. Как обычно, легко и просто при переводе ничего не бывает.

Например, по той же грамматике можно построить предложение «Раму мыла мама». Лексер выдаст [«Рама», «мыть», «мама», «.»]. По этому массиву непонятно, кто кого мыл. Если же мы построим дерево вывода, то различие будет сразу понятно.

Работа синтаксического анализатора – получить грамматику языка и массив лексем и выдать дерево построения в виде последовательности правил, которые надо применить, чтобы вывести данный текст.


# Ок, и что дальше?

## Ограниченность 

> Язык, формирует способ нашего мышления и определяет, о чём мы думаем. \
> `Бенджамин Ли Уорф`

Надеюсь, вы не забыли, что мы хотели просто посчитать `(a + b - c) / (a * 2)`, где a, b, c - просто какие-то числа. Но это слишком просто (мы же не на ассемблере пишем), поэтому я предлагаю написать собственный полноценный калькулятор. Обычно начинающие пишут нечто подобное:

~~~Python
a = float(input())
operator = input()
b = float(input())

res = 0
if operator == "+":
    res = a + b
elif operator == "-":
    res = a - b
elif operator == "*":
    res = a * b
elif operator == "/":
    res = a / b
else:
    print("error")

print(res)
~~~

Чем плох этот калькулятор? Мы можем вычислять только элементарные вещи, причём ввод идёт в неудобной форме:
~~~
456
+
123
~~~

Этот калькулятор слишком простой. Он ограничивает нашу мысль.

## Создаем нечто большее

> Измените свой язык, и вы измените свои мысли. \
> `Карл Альбрехт`

### Шаг 1

Сделаем ввод данных в одну строку:

~~~Python
import re

string = input()
tokens = re.findall(r'\S+', string) # тут будут храниться все наши токены

a = float(tokens[0])
operator = tokens[1]
b = float(tokens[2])

res = 0
if operator == "+":
    res = a + b
elif operator == "-":
    res = a - b
elif operator == "*":
    res = a * b
elif operator == "/":
    res = a / b
else:
    print("error")

print(res)
~~~

### Шаг 2

Давайте проанализируем, что происходило до этого.

Наш калькулятор требовал два числа и оператор в строго определенном порядке:

~~~
<выражение> := <число> <оператор> <число>
~~~

Предлагаю обобщить нашу грамматику до более универсальной:

~~~
<выражение> := <число> <оператор> <выражение> | <число>
~~~

Предлагаю модифицировать калькулятор, чтобы он мог вычислять такие выражения, как `2 + 3 - 5`.

Как это сделать? Ведь операторов может быть сколько угодно.

Есть такая штука, как [обратная польская запись](https://ru.wikipedia.org/wiki/Обратная_польская_запись).

Обратная польская запись - форма записи математических и логических выражений, в которой операнды расположены перед знаками операций. Также именуется как обратная бесскобочная запись, постфиксная нотация, бесскобочная символика Лукасевича, польская инверсная запись, ПОЛИЗ.

Стековой машиной называется алгоритм, проводящий вычисления по обратной польской записи. Собственно, эта стековая машина нам и нужна (забавно мы пишем машину для машины).

Отличительной особенностью обратной польской нотации является то, что все аргументы (или операнды) расположены перед знаком операции. В общем виде запись выглядит следующим образом:

* Запись набора операций состоит из последовательности операндов и знаков операций. Операнды в выражении при письменной записи разделяются пробелами.
* Выражение читается слева направо. Когда в выражении встречается знак операции, выполняется соответствующая операция над двумя последними встретившимися перед ним операндами в порядке их записи. Результат операции заменяет в выражении последовательность её операндов и её знак, после чего выражение вычисляется дальше по тому же правилу.
* Результатом вычисления выражения становится результат последней вычисленной операции.

```python
import operator

def evalRPN(tokens):
    operators = {
        '+': operator.add, 
        '-': operator.sub, 
        '*': operator.mul, 
        '/': operator.truediv
    }
    
    stack = [0]
    for token in tokens:
        if token in operators:
            op2, op1 = stack.pop(), stack.pop()
            res = operators[token](op1, op2)
            stack.append(res)
        elif token:
            stack.append(float(token))
    return stack.pop()
```

Отлично, мы научились считать, но этого мало

Нам нужно преобразовывать наш текст в понятный для машины набор команд

Если обратиться к теории, то как мы пишем математические выражения - инфиксная нотация. В инфиксной нотации, в отличие от префиксной и постфиксной, скобки, окружающие группы операндов и операторов, определяют порядок, в котором будут выполнены операции. При отсутствии скобок операции выполняются согласно правилам приоритета операторов.

Алгоритм перевода из инфиксной нотации:
~~~
* Пока есть ещё символы для чтения:
  * Читаем очередной символ.
  * Если символ является числом или постфиксной функцией (например, ! — факториал), добавляем его к выходной строке.
  * Если символ является префиксной функцией (например, sin — синус), помещаем его в стек.
  * Если символ является открывающей скобкой, помещаем его в стек.
  * Если символ является закрывающей скобкой:
    До тех пор, пока верхним элементом стека не станет открывающая скобка, выталкиваем элементы из стека в выходную строку. При этом открывающая скобка удаляется из стека, но в выходную строку не добавляется. Если стек закончился раньше, чем мы встретили открывающую скобку, это означает, что в выражении либо неверно поставлен разделитель, либо не согласованы скобки.
    * Если существуют разные виды скобок, появление непарной скобки также свидетельствует об ошибке. Если какие-то скобки одновременно являются функциями (например, [x] — целая часть), добавляем к выходной строке символ этой функции.
  * Если символ является бинарной операцией о1, тогда:
    1. пока на вершине стека префиксная функция… \
    … ИЛИ операция на вершине стека приоритетнее o1 \
    … ИЛИ операция на вершине стека левоассоциативная с приоритетом как у o1 \
    … выталкиваем верхний элемент стека в выходную строку;
    2. помещаем операцию o1 в стек.
    
* Когда входная строка закончилась, выталкиваем все символы из стека в выходную строку. В стеке должны были остаться только символы операций; если это не так, значит в выражении не согласованы скобки.
~~~

